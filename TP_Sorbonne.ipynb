{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Vectors and matrices\n",
    "from scipy import stats  # Probability distributions\n",
    "import matplotlib.pyplot as plt  # Plots\n",
    "from matplotlib import style\n",
    "import matplotlib as mpl\n",
    "try:\n",
    "    mpl.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    mpl.style.use('seaborn')\n",
    "mpl.rcParams['image.cmap'] = 'plasma'\n",
    "nice_hist = dict(bins='auto', density=True, ec='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exercice 2 : Algorithme de Metropolis <a id=\"part2\"></a>\n",
    " \n",
    " **On veut simuler (approximativement) une loi normale centrée réduite grâce à l'algorithme de Metropolis.**\n",
    "\n",
    " \n",
    " \n",
    " > **Question 1.**\n",
    " On choisit comme noyau de proposition $q$ de sorte que, pour tout $x \\in \\mathbb R$, $q(x, \\cdot)$ corresponde à la densité de la variable aléatoire $Y=x+U$ avec $U \\sim \\mathcal U_{[-1/2,1/2]}$.\n",
    " Autrement dit, $q(x, \\cdot)$ est la densité de probabilité d'aller en $y$ sachant qu'on part du point $x$. Déterminer $q(x,y)$. En déduire $q(y,x)$.\n",
    "\n",
    " >**Question 2.**\n",
    "    Traduire l'algorithme de Metropolis-Hastings dans ce cadre.\n",
    "\n",
    "\n",
    " >**Question 3.**\n",
    " Écrire une fonction `sample_metropolis(kernel, size=1, init=0.)` qui construit une chaîne de Markov de taille $n$ partant du point `init` selon l'algorithme décrit ci-avant.\n",
    " L'argument `kernel` représente la loi de $U$, ici : `kernel=stats.uniform(loc=-0.5, scale=1)`.\n",
    " La fonction devra retourner la réalisation de la chaîne et le taux d'acceptation.\n",
    " >\n",
    "\n",
    "Appliquer cet algorithme pour construire une chaîne de longueur $n=10^4$ et partant d'un point $X_0$ tiré uniformément dans $[-3,3]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10**4\n",
    "\n",
    "def sample_metropolis(kernel, size=1, init=0.):\n",
    "    unif = stats.uniform()\n",
    "    threshold = unif.rvs(size=size)  # Array of the n thresholds U_i\n",
    "    move = kernel.rvs(size=size)  # Array of the n moves from the current position\n",
    "    \n",
    "    sample = [init]\n",
    "    n_acc = 0\n",
    "    for i in range(size):\n",
    "        # Compléter\n",
    "\n",
    "        # Fin compléter\n",
    "    return np.asarray(sample), n_acc/size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "\n",
    "\n",
    "# Draw a sample with Metropolis\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "\n",
    "\n",
    "# >**Question 4.**\n",
    "# Pour la réalisation de cette chaîne, représenter un histogramme des $X_i$ auquel on superposera la densité de la loi normale centrée réduite.\n",
    "# Indiquer le taux d'acceptation dans le titre de la figure.\n",
    "# >Que pouvez-vous en dire ?\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "norm = stats.norm()\n",
    "\n",
    "x = np.linspace(-3, 3)\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "plt.title(f\"Taux d'acceptation : {rate}\");\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 5.**\n",
    "# Observer ce qu'il se passe lorsque la condition initiale est $X_0=10$.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 6.**\n",
    "# Revenons à $X_0\\sim{\\cal U}_{[-3,3]}$. Plutôt qu'une loi de proposition uniforme sur $[-1/2,1/2]$, considérer une loi uniforme sur $[-10,10]$. Qu'observez-vous ? Et avec une loi uniforme sur $[-0.1,0.1]$ ?\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# # Exercice 3 : Metropolis vs rejet <a id=\"part3\"></a>\n",
    "# >On considère la loi $G$ de densité sur $\\mathbb{R}^2$ proportionnelle à \n",
    "# $$ f(u,v) =   (\\cos u ) ^2     ( \\sin v) ^2  \\operatorname{e}^{-0.05   (u^2 + v^2)}.$$\n",
    "# >\n",
    "# >**Question 1.**\n",
    "# Définir une fonction `F(U, V)` retournant $f(U, V)$ et utiliser le code ci-dessous pour afficher une représentation 3D de $f$ sur $[-5,5]\\times[-5,5]$.\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def plot_surf(U, V, Z, figsize=(15, 12)):\n",
    "    fig, ax = plt.subplots(figsize=figsize, subplot_kw=dict(projection='3d'))\n",
    "    # ax.view_init(30, 120)\n",
    "    plt.rcParams['axes.grid'] = False\n",
    "    surf = ax.plot_surface(U, V, Z, rstride=1, cstride=1, cmap=\"coolwarm\", linewidth=0)\n",
    "    ax.contourf(U, V, Z, zdir='z', offset=Z.max()+1, cmap=\"coolwarm\", alpha=0.5)\n",
    "    ax.set_zlim(top=Z.max()+1)\n",
    "    fig.colorbar(surf)\n",
    "    ax.set_xlabel('u')\n",
    "    ax.set_ylabel('v')\n",
    "    ax.set_zlabel('z')\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "def F(U, V):\n",
    "    # Compléter\n",
    "\n",
    "    # Fin compléter\n",
    "\n",
    "u = np.linspace(-5, 5, num=100)\n",
    "v = np.linspace(-5, 5, num=100)\n",
    "U, V = np.meshgrid(u, v)  # All possible pairs from u and v\n",
    "\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "plot_surf(U, V, Z);\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 2.**\n",
    "# On veut simuler (approximativement) selon la loi $G$ en utilisant l'algorithme de Metropolis-Hastings.\n",
    "# >Partant de $x=(u,v)$, on considère le noyau de proposition $q$ défini de sorte que $q(x,\\cdot)$ corresponde à la densité de $Y=x+\\sigma W$, où $\\sigma>0$ est un paramètre de réglage et $W\\sim{\\cal N} \\left(\\binom 00,I_2 \\right)$, loi gaussienne centrée réduite dans $\\mathbb{R}^2$.\n",
    "# >Expliquer pourquoi nous sommes dans le cadre de l'algorithme de Metropolis.\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 3.**\n",
    "# Implémenter l'algorithme de Metropolis. On utilisera le noyau de transition $q$ ci-dessus avec $\\sigma=1$. On pourra par exemple prendre comme initialisation $X_1=(0,0)$ et considérer une chaîne $(X_k)_{0\\leq k\\leq n}$ de longueur $n=10^4$. En fin de simulation, afficher le taux global d'acceptation sur l'ensemble des mutations proposées.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "def f(x):\n",
    "    u, v = x\n",
    "    return F(u, v)\n",
    "\n",
    "def sample_metropolis_2d(kernel, size=1, init=(0., 0.)):\n",
    "    unif = stats.uniform()\n",
    "    threshold = unif.rvs(size=size-1)  # Array of the n-1 thresholds U_i\n",
    "    move = kernel.rvs(size=size-1)  # Array of the n-1 moves from the current position\n",
    "    \n",
    "    sample = [init]\n",
    "    n_acc = 0\n",
    "    for i in range(size-1):\n",
    "        # Compléter\n",
    "\n",
    "        # Fin compléter\n",
    "    \n",
    "    return np.asarray(sample), n_acc/size\n",
    "\n",
    "n = 10**4\n",
    "sigma = 1\n",
    "\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "print(f\"Taux d'acceptation : {rate}\")\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 4.**\n",
    "# Sur le graphe de $f$ par lignes de niveau (`plt.contourf(U, V, Z, cmap=cm.coolwarm, alpha=0.5)`), superposer les points de la chaîne. Faire la même chose avec $\\sigma$ grand, par exemple $\\sigma=10$, et commenter. Idem avec $\\sigma$ petit, par exemple $\\sigma=0.1$. Afficher les taux d'acceptation dans les deux cas.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, sigma in enumerate([0.1, 1, 10]):\n",
    "    # Compléter\n",
    "\n",
    "    # Fin compléter\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.contourf(U, V, Z, cmap=\"coolwarm\", alpha=0.5)\n",
    "    # Compléter\n",
    "\n",
    "    # Fin compléter\n",
    "    plt.xlim([U.min(), U.max()])\n",
    "    plt.ylim([V.min(), V.max()])\n",
    "    plt.title(f\"$\\\\sigma={sigma:.1f}$, taux d'acceptation : {rate:.2f}\")\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 5.**\n",
    "# Proposer une méthode de rejet pour simuler suivant la loi $G$ à partir d'une loi instrumentale gaussienne. Comme en question précédente, superposer un échantillon de grande taille simulé par cette méthode aux niveaux de la fonction $f$ pour vérifier visuellement le bon fonctionnement de l'algorithme.\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "aux = stats.multivariate_normal(cov=10*np.eye(2))\n",
    "unif = stats.uniform()\n",
    "\n",
    "n = 10**3\n",
    "\n",
    "sample = []\n",
    "n_tot = 0\n",
    "for i in range(n):\n",
    "    candidate = aux.rvs()\n",
    "    n_tot += 1\n",
    "    # Compléter\n",
    "\n",
    "    # Fin compléter\n",
    "    sample.append(candidate)\n",
    "sample = np.asarray(sample)\n",
    "rate = n / n_tot\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.contourf(U, V, Z, cmap=\"coolwarm\", alpha=0.5)\n",
    "plt.scatter(*sample.T, c='r', s=1)\n",
    "plt.xlim([U.min(), U.max()])\n",
    "plt.ylim([V.min(), V.max()])\n",
    "plt.title(f\"Taux d'acceptation : {rate:.2f}\");\n",
    "\n",
    "\n",
    "# >**Question 6.**\n",
    "# Des deux méthodes, laquelle vous semble préférable ?\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# # Exercice 4 : Algorithme de Gibbs <a id=\"part4\"></a>\n",
    "# >Soit $(X,Y)$ un couple aléatoire de densité jointe sur $\\mathbb R^2$, $f : (x,y) \\mapsto e^{-y}\\mathbf{1}_{0\\leq x\\leq y}$.\n",
    "# >\n",
    "# >**Question 1.**\n",
    "# Déterminer la loi marginale de $X$.\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 2.**\n",
    "# Sachant $X=x\\geq0$, déterminer la densité conditionnelle de $Y | X=x$, notée $f_{Y | X=x}$. Quelle loi reconnaissez-vous ?\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 3.**\n",
    "# En déduire une méthode pour simuler une réalisation du couple aléatoire $(X,Y)$. L'implémenter pour simuler un échantillon de couples $(X_1,Y_1),\\dots,(X_n,Y_n)$ de taille $n=1000$. Représenter le nuage de points ainsi obtenu. \n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "n = 1000\n",
    "\n",
    "exp = stats.expon()\n",
    "\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X, Y, s=1)\n",
    "\n",
    "\n",
    "# >**Question 4.**\n",
    "# Sachant $Y=y\\geq 0$, déterminer la densité conditionnelle de $X | Y=y$, notée $f_{X | Y=y}$. Quelle loi reconnaissez-vous ?\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 5.**\n",
    "# En partant par exemple du point $(x_0,y_0)=(0,1)$, proposer un échantillonneur de Gibbs pour obtenir une trajectoire $\\left( (X_1, Y_1),\\dots,(X_n, Y_n) \\right)$ de densité cible $f$. Représenter le nuage de points ainsi obtenu.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "unif = stats.uniform()\n",
    "\n",
    "X, Y = [0], [1]\n",
    "for i in range(n-1):\n",
    "    # Compléter\n",
    "\n",
    "    # Fin compléter\n",
    "    \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X, Y, s=1)\n",
    "\n",
    "\n",
    "# >**Question 6.**\n",
    "# Des deux méthodes proposées, laquelle choisiriez-vous pour simuler selon la densité $f$ ?\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# # Exercice 5 : Algorithme de Metropolis pour l'échantillonnage d'une loi a posteriori <a id=\"part5\"></a>\n",
    "# >On considère le modèle bayésien :\n",
    "# \\begin{cases}\n",
    "#     \\boldsymbol \\theta \\sim {\\cal U}_{[0,1]} \\\\\n",
    "#     (X_1, \\dots, X_n) | \\boldsymbol \\theta \\sim \\left( \\boldsymbol \\theta \\mathcal N(1, 1) + (1-\\boldsymbol \\theta) \\mathcal N(-1, 1) \\right)^{\\otimes n}.\n",
    "#     %\\mathbf X | \\boldsymbol \\theta \\sim \\left( \\boldsymbol \\theta N(1, 1) + (1-\\boldsymbol \\theta) N(-1, 1) \\right)^{\\otimes n}.\n",
    "# \\end{cases}\n",
    "# Notons $\\phi$ la densité de $\\mathcal N(0, 1)$. Ainsi, sachant $\\boldsymbol \\theta = \\theta$,  $X_1$ a pour densité $\\theta \\phi(x-1) + (1-\\theta) \\phi(x+1)$.\n",
    "# On remarque aussi que, sachant $\\boldsymbol \\theta = \\theta$, $X_1\\overset{\\mathcal{L}}{=} Z Y_1 + (1-Z) Y_{-1}$, où $Y_1, Y_{-1}$ et $Z$ sont trois variables aléatoires indépendantes de lois respectives $\\mathcal N(1, 1)$, $\\mathcal N(-1, 1)$ et $\\mathcal B(\\theta)$.\n",
    "# >\n",
    "# >**Question 1.**\n",
    "# Soit $\\theta_0$ une réalisation de $\\boldsymbol \\theta$.\n",
    "# Pour $n=100$, générer une réalisation de $X_1,\\dots,X_n$ selon le mélange ci-dessus pondéré par $\\theta_0$.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "prior = stats.uniform()\n",
    "theta0 = prior.rvs()\n",
    "\n",
    "ber = stats.bernoulli(theta0)\n",
    "normp = stats.norm(loc=1)\n",
    "normm = stats.norm(loc=-1)\n",
    "\n",
    "n = 100\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "\n",
    "print(f'theta0 = {theta0}')\n",
    "plt.hist(X, **nice_hist);\n",
    "\n",
    "\n",
    "# >**Question 2.**\n",
    "# Expliciter la loi a posteriori $\\Pi[\\cdot | \\mathbf X]$ et l'estimateur de Bayes $\\hat \\theta_n$ pour la perte quadratique.\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 3.**\n",
    "# En déduire un estimateur Monte-Carlo $\\hat\\theta_n^N$ de la réalisation de l'estimateur de Bayes $\\hat\\theta_n$. L'implémenter pour $N=500$ par exemple. \n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "N = 500\n",
    "\n",
    "# Compléter\n",
    "\n",
    "# Fin compléter\n",
    "\n",
    "plt.plot(np.arange(1, N+1), estMC, label = \"Estimateur MC\")\n",
    "plt.axhline(theta0, color=\"red\", label=\"$\\\\theta_0$\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "# >**Question 4.**\n",
    "# >On souhaite générer un échantillon suivant la loi a posteriori $\\Pi[\\cdot | \\mathbf X]$. On adopte pour cela la méthode de Metropolis-Hastings (qui fournira donc approximativement un échantillon de loi $\\Pi[\\cdot | \\mathbf X]$, i.e. une trajectoire de loi cible $\\Pi[\\cdot | \\mathbf X]$) avec comme noyau de proposition $q$, de sorte que $q(\\theta,\\theta')=\\mathbf 1_{[0,1]}(\\theta')$.\n",
    "# Quelle est la loi de proposition ?\n",
    "# Que vaut le rapport de Metropolis-Hastings $r(\\theta,\\theta')$ ?\n",
    "# >Avec la condition initiale $\\boldsymbol \\theta_1=1/2$, implémenter l'algorithme pour une chaîne de longueur $m=10^4$ et représenter un estimateur de la densité de la trajectoire $(\\boldsymbol \\theta_1,\\dots,\\boldsymbol \\theta_m)$. Donner le taux global d'acceptation sur l'ensemble des mutations proposées.\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Answer\n",
    "m = 10**4\n",
    "init = 0.5\n",
    "\n",
    "threshold = prior.rvs(size=m-1)\n",
    "move = prior.rvs(size=m-1)\n",
    "\n",
    "sample = [init]\n",
    "for i in range(m-1):\n",
    "    # Compléter\n",
    "\n",
    "    # Fin compléter\n",
    "\n",
    "plt.hist(sample, **nice_hist)\n",
    "print(f\"Taux d'acceptation : {len(np.unique(sample)) / m:.2f}\")\n",
    "\n",
    "\n",
    "# **Réponse :**\n",
    "# …\n",
    "\n",
    "# >**Question 5.**\n",
    "# Mêmes questions en considérant le noyau de transition correspondant à $\\boldsymbol \\theta' = \\boldsymbol \\theta+U/\\sqrt{n}$ (modulo 1), avec $U \\sim \\mathcal U_{[-1,1]}$.\n",
    "\n",
    "\n",
    "\n",
    "# Exercice 6 : Slice sampler <a id=\"part6\"></a>\n",
    ">On considère la fonction $f : (u,x) \\in \\mathbb R^2 \\mapsto \\mathbf 1_{0<u<\\frac{1}{2}\\exp \\left(-\\sqrt{x} \\right)}$.\n",
    ">\n",
    ">**Question 1.**\n",
    "Montrer que $g : x \\mapsto \\frac{1}{2}\\exp \\left(-\\sqrt{x} \\right)\\mathbf 1_{x>0}$ est une densité sur $\\mathbb{R}$. En déduire que $f$ est une densité sur $\\mathbb{R}^2$.\n",
    "\n",
    "\n",
    "\n",
    ">**Question 2.**\n",
    "Soit $(U, X)$ de densité $f$.\n",
    "Déterminer, pour tout $(u, x) \\in \\mathbb R_+^2$, les lois conditionnelles de $U | X=x$ et $X | U=u$.\n",
    "\n",
    "\n",
    "# >**Question 3.**\n",
    "# En partant du point $(U_1,X_1)=(1/(4e),1)$, implémenter un échantillonneur de Gibbs pour obtenir une trajectoire $(U_1,X_1),\\dots,(U_n,X_n)$ de taille $n=1000$ et de densité cible $f$.\n",
    "\n",
    "\n",
    "\n",
    ">**Question 4.**\n",
    "Sur un même graphe, représenter la densité $g$ et un estimateur de la densité obtenu à partir de la trajectoire $X_1,\\dots,X_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
